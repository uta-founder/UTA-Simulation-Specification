## Executive Brief

**Objective:** Develop an Equilibrium Solver Engine to compute simultaneous market-clearing prices for a 50-country, 30-sector simulation (~3,000 markets) in under 5 seconds, even under extreme shocks. We evaluated classic and modern algorithms – *Tâtonnement* (price adjustment), Newton-Raphson (Jacobian-based root-finding), and PATH (complementarity solver) – for speed, robustness, and GPU acceleration. **Recommendation:** Use a **damped Newton-Raphson method with global convergence enhancements** (inspired by the PATH solver) as the primary algorithm, implemented with GPU-enabled Python libraries (e.g. JAX or PyTorch). Newton’s method converges rapidly near the solution (quadratic convergence) and handles large systems efficiently [pages.cs.wisc.edu](https://pages.cs.wisc.edu/~ferris/techreports/cstr1179.pdf#:~:text=is%20perhaps%20the%20most%20well,Recently%2C%20Grippo). To ensure stability under shocks like 200% tariffs or embargoes, we incorporate safeguards (line search, trust regions or homotopy steps) to avoid divergence [pages.cs.wisc.edu](https://pages.cs.wisc.edu/~ferris/techreports/cstr1179.pdf#:~:text=is%20perhaps%20the%20most%20well,Recently%2C%20Grippo). This hybrid approach offers the best of both worlds – the speed of Newton’s method and the robustness of gradual price adjustment – enabling real-time performance.

**Rationale:** Newton-based algorithms leverage derivative information (sensitivities of supply/demand to price) to find equilibrium in only a few iterations, whereas simpler “price adjustment” methods require many small steps [copsmodels.com](https://www.copsmodels.com/ftp/workpapr/g-214.pdf#:~:text=match%20at%20L665%203,Raphson). On modern NVIDIA DGX GPUs, we can parallelize the heavy computations (Jacobian matrix operations, solving linear systems) to easily meet the <5s target. The solver will be coded in Python using open-source tools (e.g. JAX for auto-differentiation), avoiding costly proprietary software. If the primary solver ever struggles (e.g. non-convergence in a highly disrupted scenario), a **fallback** strategy will automatically kick in – for example, a slower but reliable tatonnement process or stepwise shock implementation – to guarantee a solution. This ensures the simulation remains **fast, robust, and reproducible** with each run.

## Plain-English Mechanism

**How it works:** Imagine an “auctioneer” adjusting prices across all markets simultaneously until supply equals demand everywhere [fiveable.me](https://fiveable.me/introduction-to-mathematical-economics/unit-11/walrasian-equilibrium/study-guide/GVSDRkPHiJ5fIw9a#:~:text=,or%20demand%20in%20any%20market) [fiveable.me](https://fiveable.me/introduction-to-mathematical-economics/unit-11/walrasian-equilibrium/study-guide/GVSDRkPHiJ5fIw9a#:~:text=Market%20clearing%20conditions). Our solver automates this process with advanced math to reach equilibrium almost instantly. Here’s the intuition: we start with an initial guess of prices for all ~3,000 markets. We then check each market’s imbalance (excess demand = demand – supply). If a good is in excess demand, the algorithm will **raise its price**; if there’s excess supply, it will **lower the price**, much like Walras’s classic tâtonnement process [fiveable.me](https://fiveable.me/introduction-to-mathematical-economics/unit-11/walrasian-equilibrium/study-guide/GVSDRkPHiJ5fIw9a#:~:text=Price%20adjustment%20mechanism). However, unlike naive tatonnement that nudges prices little by little, our algorithm uses the **Newton-Raphson technique** to jump smartly to the equilibrium. Newton’s method effectively asks: “Given the current prices and imbalances, how should we adjust all prices, considering how sensitive each market’s supply and demand are to price changes?” By using the slope of excess demand (the first derivative) in each market, it computes an optimal price correction in one step, rather than inching along. This dramatically accelerates convergence – akin to cutting across a winding road to reach the destination faster. The price updates continue iteratively until **no market has any significant excess demand or supply**, i.e. all markets clear. At equilibrium, we have a set of prices where every good’s supply equals demand and no further price adjustments are needed [fiveable.me](https://fiveable.me/introduction-to-mathematical-economics/unit-11/walrasian-equilibrium/study-guide/GVSDRkPHiJ5fIw9a#:~:text=Market%20clearing%20conditions).

**Extreme shocks:** Under extreme conditions (like a sudden 200% tariff or a full trade embargo), the model’s supply/demand landscape changes drastically. Our solver remains stable by being a bit more cautious in how it updates prices when imbalances are huge. In plain terms, we “don’t overshoot the turn.” The Newton-based updates can be damped (scaled down) if a price correction seems too large, ensuring the algorithm approaches the new equilibrium steadily rather than bouncing erratically. This is analogous to taking smaller steps when the terrain is rough. If an embargo makes some trade flows drop to zero, the solver will recognize that certain prices have a natural floor (you can’t go below zero) – in those cases, it treats the problem as a **complementarity** situation (either price adjusts or the surplus persists) rather than a smooth equation. The PATH solver logic (if used) inherently handles such cases by treating them as mixed inequalities [pages.cs.wisc.edu](https://pages.cs.wisc.edu/~ferris/techreports/cstr1179.pdf#:~:text=The%20Path%20solver%20is%20an,is%20shown%20to%20be%20globally), but even in our custom implementation we can enforce non-negativity of prices and key quantities. Overall, the mechanism guarantees that even wild shocks won’t crash the solver; instead, the convergence might slow slightly (or take a few intermediate steps), but it will find the new balance point reliably.

**GPU acceleration:** All these calculations – evaluating thousands of supply/demand functions and their sensitivities – happen in parallel on the GPU. Think of the GPU as a super-fast marketplace scoreboard updating all prices at once. Using libraries like JAX or PyTorch, we can compute each market’s excess demand and the Jacobian matrix (which captures how each price affects each market’s balance) in a vectorized way, leveraging hundreds of GPU cores. This means whether we’re adjusting 300 or 3,000 prices, the updates occur simultaneously, drastically reducing solve time. Modern GPU-based approaches to market equilibrium have shown **significant efficiency gains**, solving large problems that were previously impractical [arxiv.org](https://arxiv.org/html/2506.06258v1#:~:text=framework%20that%20integrates%20the%20primal,and%20applicability%20of%20market%20equilibrium). In short, the solver is designed to harness heavy computation power so that even a complex global economy model converges in seconds – crucial for an interactive simulation platform where users might impose shocks and expect instant feedback.

## Technical Specification

**Equilibrium model:** We formulate the market-clearing conditions as a system of nonlinear equations. For each of the ~3,000 markets (e.g. the wheat market in Canada, the steel market in China, etc.), let zi(p)z_i(p)zi(p) denote the **excess demand** at price vector ppp (i.e. supply minus demand for good *i*). An equilibrium is defined by zi(p∗)=0z_i(p^*) = 0zi(p∗)=0 for all markets *i*, meaning no excess supply or demand remains [fiveable.me](https://fiveable.me/introduction-to-mathematical-economics/unit-11/walrasian-equilibrium/study-guide/GVSDRkPHiJ5fIw9a#:~:text=,degree%20zero%2C%20and%20Walras%27%20Law). We have as many equations as prices, so in principle a unique solution (up to choice of numéraire) is determined by solving F(p)=0F(p) = 0F(p)=0 where F(p)=(z1(p),z2(p),…,z3000(p))F(p) = (z_1(p), z_2(p), \dots, z_{3000}(p))F(p)=(z1(p),z2(p),…,z3000(p)). These equilibrium conditions inherently account for production decisions, consumption, and trade flows given prices – for example, if prices shift, firms adjust output and consumers shift purchases, altering $z_i$. The model assumes standard economic behaviors (firms cost-minimize, consumers maximize utility) so that supply and demand functions are well-behaved (continuous, downward-sloping demand, etc.), providing the smoothness needed for Newton’s method and ensuring a solution exists under usual conditions [fiveable.me](https://fiveable.me/introduction-to-mathematical-economics/unit-11/walrasian-equilibrium/study-guide/GVSDRkPHiJ5fIw9a#:~:text=,uniqueness%20or%20stability%20of%20equilibrium). (If extreme shocks violate some assumptions – e.g. making a good unwanted – the complementarity handling allows the model to drop that market out with a zero price or quantity as needed.)

**Primary algorithm – Damped Newton-Raphson:** Newton’s method solves F(p)=0F(p)=0F(p)=0 by iteratively updating ppp. At iteration $n$, given current guess $p_n$, we compute the **Jacobian matrix** $J = \nabla F(p_n)$ (an $N \times N$ matrix of partial derivatives, here ~$3000\times3000$). This matrix $J$ tells us how each market’s imbalance would change if we tweak each price. Newton’s update step is:

pn+1=pn−J−1F(pn),p_{n+1} = p_n - J^{-1} F(p_n),pn+1=pn−J−1F(pn),

meaning we solve the linear approximation $J , \Delta p = -F(p_n)$ for $\Delta p$ and apply that as a price adjustment  [jax.quantecon.org](https://jax.quantecon.org/newtons_method.html#:~:text=%284.1%29%23%5C%5Bp_%7Bn%2B1%7D%20%3D%20p_n%20,p_n)  [jax.quantecon.org](https://jax.quantecon.org/newtons_method.html#:~:text=f_jac%20%3D%20jax,1%20n%20%3D%200). In essence, it finds the price correction $\Delta p$ that would drive all excess demands to zero *if* the system were linear. For well-behaved economies, this quickly zooms in on the true equilibrium. Newton’s method has **excellent convergence properties** near the solution – errors shrink quadratically, often solving in only 5–10 iterations even for large $N$  [pages.cs.wisc.edu](https://pages.cs.wisc.edu/~ferris/techreports/cstr1179.pdf#:~:text=is%20perhaps%20the%20most%20well,Recently%2C%20Grippo). However, pure Newton can be fragile if the initial guess is poor or the shock is very large: it might propose a step that is too extreme, leading to divergence or negative prices. To mitigate this, we implement a *damped Newton*: if any update $\Delta p$ is too large (e.g. would yield negative prices or overshoot by making excess demand flip signs wildly), we scale it down (line search)  [pages.cs.wisc.edu](https://pages.cs.wisc.edu/~ferris/techreports/cstr1179.pdf#:~:text=globally%20convergent,without%20sacri%0Ccing%20the%20global%20convergence). This stabilization is akin to the PATH solver’s approach, which constructs a piecewise-linear path toward the Newton point and uses a non-monotonic line search for global convergence [pages.cs.wisc.edu](https://pages.cs.wisc.edu/~ferris/techreports/cstr1179.pdf#:~:text=The%20Path%20solver%20is%20an,is%20shown%20to%20be%20globally) [pages.cs.wisc.edu](https://pages.cs.wisc.edu/~ferris/techreports/cstr1179.pdf#:~:text=Newton%20point%3B%20a%20step%20length,and%20extensive%20computational%20results%20obtained). With these safeguards, the method becomes **globally convergent** from any reasonable starting point, while retaining Newton’s speed. In practice, we can use the previous equilibrium’s prices as a starting guess for the next scenario, which will often be close, making convergence very fast. For entirely new scenarios, a heuristic initial price vector (like using base-year prices or equalizing supply-demand ratios) can be used to kick off the iterations.

**Alternative algorithms considered:**

- *Tâtonnement (price adjustment)* – We examined the classical iterative scheme pn+1,i=pn,i+α zi(pn)p_{n+1,i} = p_{n,i} + \alpha \, z_i(p_n)pn+1,i=pn,i+αzi(pn), which raises prices for excess demand and lowers for excess supply [fiveable.me](https://fiveable.me/introduction-to-mathematical-economics/unit-11/walrasian-equilibrium/study-guide/GVSDRkPHiJ5fIw9a#:~:text=Price%20adjustment%20mechanism). This method is **intuitively simple and robust**: by taking small $\alpha$ steps, it will eventually converge given standard stability conditions (e.g. gross substitutability) [fiveable.me](https://fiveable.me/introduction-to-mathematical-economics/unit-11/walrasian-equilibrium/study-guide/GVSDRkPHiJ5fIw9a#:~:text=,adjustment%20parameters%20and%20market%20characteristics). However, it converges **linearly at best** – for example, to halve the disequilibrium error you often must double the number of iterations  [copsmodels.com](https://www.copsmodels.com/ftp/workpapr/g-214.pdf#:~:text=match%20at%20L665%203,Raphson) – making it slow for real-time use. Our tests indicate that with ~3,000 markets, a naïve tatonnement could require hundreds or thousands of iterations for tough shocks, which even on a GPU might push beyond a few seconds. We therefore use tatonnement logic only as a backup or as part of a homotopy strategy (gradually applying a shock in stages). It provides a safety net for convergence but is not the primary workhorse due to its slower speed of convergence  [copsmodels.com](https://www.copsmodels.com/ftp/workpapr/g-214.pdf#:~:text=3.%20Compared%20to%20Newton,Raphson).
- *PATH Solver (complementarity)* – PATH is a sophisticated algorithm for mixed complementarity problems, essentially a **stabilized Newton method** tailored to handle inequalities and bound constraints [pages.cs.wisc.edu](https://pages.cs.wisc.edu/~ferris/techreports/cstr1179.pdf#:~:text=The%20Path%20solver%20is%20an,is%20shown%20to%20be%20globally). It would directly accommodate cases like price floors or quantity rationing by treating them as complementary slackness conditions. PATH is very robust and has been used in many CGE models via GAMS/MPSGE. We considered using PATH through the NEOS server (a free online service) [neos-server.org](https://neos-server.org/neos/solvers/cp:PATH/GAMS.html#:~:text=PATH%20,in%20AMPL%20or%20GAMS%20format). However, relying on an external server for real-time simulation is impractical (network latency and job queue times). Moreover, PATH’s standalone software isn’t open-source and a commercial license could exceed our budget. Instead, we mimic its key ideas (damped Newton, handling of bound constraints) in our solver. If needed, we can still use NEOS/ PATH as a **validation tool** during development – e.g. submit our equilibrium equations to NEOS’s PATH solver to verify solutions [neos-server.org](https://neos-server.org/neos/solvers/cp:PATH/GAMS.html#:~:text=The%20NEOS%20Server%20offers%20PATH,version%20of%20the%20PATH%20solver) [neos-server.org](https://neos-server.org/neos/solvers/cp:PATH/AMPL.html#:~:text=The%20NEOS%20Server%20offers%20PATH,version%20of%20the%20PATH%20solver) – but it won’t be in the production loop.

**GPU implementation and performance:** All core computations are implemented via high-performance linear algebra on the GPU. Using JAX, for example, we define the excess demand function $F(p)$ and rely on **automatic differentiation** to get the Jacobian efficiently [jax.quantecon.org](https://jax.quantecon.org/newtons_method.html#:~:text=Instead%20of%20coding%20the%20Jacobian,jax.jacobian). This saves us from coding derivatives by hand and ensures accuracy. JAX’s JIT compilation will optimize the evaluation of $F(p)$ and $J(p)$ across 3,000 markets, and `jax.linalg.solve` (or equivalent in PyTorch/TensorFlow) will leverage GPU-optimized solvers for the linear Newton step [jax.quantecon.org](https://jax.quantecon.org/newtons_method.html#:~:text=f_jac%20%3D%20jax,1%20n%20%3D%200). Given the moderate size of the Jacobian (9 million elements if dense), a direct solve is feasible within a fraction of a second on modern GPUs. The Blackwell-architecture DGX system (with unified memory) further helps by comfortably holding all data in GPU memory and handling any CPU-GPU transfers seamlessly. We anticipate that each Newton iteration will take only tens of milliseconds; even with 5–10 iterations plus overhead, the total solve time should easily fit under 5 seconds. In fact, recent research on first-order methods for large market equilibria demonstrates that GPUs can drastically *expand* solvable scales and speed [arxiv.org](https://arxiv.org/html/2506.06258v1#:~:text=framework%20that%20integrates%20the%20primal,and%20applicability%20of%20market%20equilibrium) – our problem size (~3k variables) is well within what’s considered “large-scale” in such studies, so we are in a safe zone for performance. We will also exploit any sparsity in the Jacobian: many markets only connect to certain prices (e.g. an agricultural market might not directly affect a mining sector in another country except through income effects). Using sparse linear algebra or block decomposition could further speed up solves, though even dense methods should be fast enough.

Regarding the idea of formulating the equilibrium as a **differentiable neural network**: the solver itself can be viewed as an *implicit layer* in a neural net, where inputs (policy shocks) map to outputs (equilibrium prices) through a fixed-point computation. We can differentiate through this equilibrium via implicit differentiation if needed for sensitivity analysis or AI training. However, we do *not* train a separate neural network to approximate the equilibrium; we solve it directly via economics-informed algorithms. This ensures **exact satisfaction of constraints** and transparency. In short, our approach uses *neural-network libraries* (TensorFlow/PyTorch/JAX) as computing tools, but the solution procedure remains a numerical root-finding algorithm, not a black-box learned approximation. No custom CUDA kernels are needed – we leverage existing GPU ops (matrix solves, autodiff) which are highly optimized.

**Open-source and low-cost solver tools:** We prioritize open-source frameworks both for cost and flexibility. Key options we surveyed:

- **SciPy Optimize (Python):** SciPy’s `optimize.root` function (e.g. Powell’s hybrid method) can solve systems of equations and has been used in smaller CGE models. It’s free and easy to use, but it’s CPU-only and would not by itself meet our speed requirement for 3k equations. We will incorporate SciPy’s solvers only as a secondary check or for prototyping small cases.
- **Pyomo + Solvers:** Pyomo is an open-source modeling library for optimization problems. It can express equilibrium conditions (including complementarity conditions via its `Complementarity` component) and then call solvers like IPOPT (for nonlinear equations) or even PATH (if available) [osti.gov](https://www.osti.gov/servlets/purl/1771935#:~:text=The%20pyomo%20command%20can%20execute,the%20munson1%20problem%20from). Using Pyomo with IPOPT is a viable open-source route; IPOPT can solve nonlinear systems as an optimization (minimizing sum of squared equations, for instance). However, IPOPT is also CPU-based and might struggle to hit 5 seconds unless the problem is sparsely structured. We found that a custom GPU approach gives us more direct control. Pyomo could still be useful for modeling and verifying the formulation or exploring scenario variants. If PATH is needed for tricky complementarity aspects, one could use Pyomo/NEOS to tap PATH [neos-server.org](https://neos-server.org/neos/solvers/cp:PATH/AMPL.html#:~:text=The%20NEOS%20Server%20offers%20PATH,version%20of%20the%20PATH%20solver), but again that’s more for validation than real-time use.
- **GEKKO (Python):** GEKKO is a high-level interface to the APMonitor suite of solvers, which includes nonlinear and mixed-integer solvers [github.com](https://github.com/BYU-PRISM/GEKKO#:~:text=GEKKO%20provides%20a%20user,quadratic%2C%20nonlinear%2C%20and%20mixed). It is free and user-friendly, automatically choosing appropriate algorithms for systems of equations. We tested GEKKO on a small equilibrium example and found it can find solutions via its nonlinear solver (likely IPOPT or APOPT under the hood). Yet, similar to Pyomo, it doesn’t utilize GPU and would be hard-pressed to solve a 3000-variable system in under 5 seconds consistently. It’s a good tool for smaller problems or for team members less familiar with writing custom solvers, but for our scale and speed needs, we lean toward a lower-level solution.
- **Commercial solvers (<$300):** Most commercial optimization solvers (GAMS, CONOPT, KNITRO, etc.) exceed our budget or are not tailored for GPU use. One possibility was **Artelys Knitro**, which has excellent nonlinear solving capabilities and sometimes promotional academic pricing, but its standard commercial license is costly. Given our preference for open-source and the fact that we have powerful hardware on hand, we didn’t identify a sub-$300 proprietary solver that clearly outperforms our chosen approach.

**Conclusion of tech approach:** By using a damped Newton algorithm implemented in a GPU-accelerated autodiff framework, we expect to achieve **fast convergence (on the order of milliseconds per iteration)** and **robust global behavior** for even extreme policy shocks. Newton’s method (with safeguards) is the core solver for simultaneously clearing all markets [fiveable.me](https://fiveable.me/introduction-to-mathematical-economics/unit-11/walrasian-equilibrium/study-guide/GVSDRkPHiJ5fIw9a#:~:text=Market%20clearing%20conditions), while simpler iterative methods serve as backups to guarantee convergence if needed [copsmodels.com](https://www.copsmodels.com/ftp/workpapr/g-214.pdf#:~:text=3.%20Compared%20to%20Newton,Raphson). This approach is not only cost-effective (built entirely on free tools) but also maintainable and transparent, as we can log convergence diagnostics and adjust the algorithm as the model evolves.

## Implementation Checklist

To build and integrate the Equilibrium Solver Engine, we propose the following implementation plan:

1. **Define Model Equations:** Translate the economic model into mathematical functions. For the prototype, start with a *toy model* (e.g. 3 countries × 5 sectors) to keep things tractable. Specify equations for supply, demand, and market-clearing for each good. Ensure differentiability of these equations (use smooth approximations for any kinks, or formulate as complementarity for exact zeros). Identify exogenous inputs (tariff rates, endowments, etc.) and parameters (elasticities, technology coefficients). Confirm that the number of independent equations equals the number of endogenous price variables [fiveable.me](https://fiveable.me/introduction-to-mathematical-economics/unit-11/walrasian-equilibrium/study-guide/GVSDRkPHiJ5fIw9a#:~:text=Market%20clearing%20conditions) (adjust closure rules if needed).
2. **Select Solver Framework:** We will implement the solver in Python using a GPU-friendly library. **Preferred choice: JAX** (or TensorFlow 2.x) for its strong auto-differentiation and JIT capabilities. JAX allows us to write the excess demand function $F(p)$ almost in analytical form and get $J(p)$ via `jax.jacobian` [jax.quantecon.org](https://jax.quantecon.org/newtons_method.html#:~:text=Instead%20of%20coding%20the%20Jacobian,jax.jacobian). It also has a linear solver (`jax.numpy.linalg.solve`) that will run on GPU. Alternatively, **PyTorch** could be used; we would then either manually compute Jacobians with `autograd.functional.jacobian` or use PyTorch’s `LBFGS` optimizer to minimize the norm of $F(p)$. We choose JAX for now due to its cleaner support for custom solvers and proven success in similar equilibrium computations [jax.quantecon.org](https://jax.quantecon.org/newtons_method.html#:~:text=Iteration%20starts%20from%20initial%20guess,p_0). Ensure the development environment on the DGX is set up with the chosen library and CUDA support.
3. **Implement Newton Solver:** Code a function that takes in a guess $p$ and returns an improved $p$ using the Newton update. This will involve computing $F(p)$ and $J(p)$ (via autodiff). Implement a robust *line search*: after solving $J \Delta p = -F(p)$, if any component of $\Delta p$ is too large (we can define thresholds like no price changes by more than, say, 50% in one step), then scale $\Delta p$ down and check if it reduces the residual $|F(p)|$. Use a merit function (e.g. ½$|F(p)|^2$) to ensure the step actually improves or use PATH’s non-monotonic strategy (allow a slight increase occasionally but overall trend down) [pages.cs.wisc.edu](https://pages.cs.wisc.edu/~ferris/techreports/cstr1179.pdf#:~:text=globally%20convergent,without%20sacri%0Ccing%20the%20global%20convergence). Also, enforce **non-negativity** of prices by projecting any $p_i$ that would go negative to a small positive number (or handle via complementarity equations: if a price hits zero, remove the corresponding equation to avoid negative supply). Set iteration stopping criteria: e.g. stop when maximum |excess demand| < tolerance (very close to zero) or when price changes become negligible. Include a max iteration cap (~15–20 iterations); if reached without convergence, that triggers the fallback.
4. **Prototype on Toy Model:** Apply the solver to the 3x5 toy model. Use realistic sample data (e.g. input-output coefficients, elasticities) but keep it simple (perhaps Cobb-Douglas utilities and CES production) so we have known equilibrium solutions to compare. Verify the solver finds the correct equilibrium prices and that the derived outputs (production, trade flows) make sense (e.g. no negative outputs, higher tariffs leading to expected price changes). Evaluate convergence behavior: does it converge in <15 iterations? Are any damped steps needed? This step will build confidence and allow tuning of solver parameters (damping factors, tolerances) in a controlled setting. We can also compare with alternative solvers here: for example, run the same toy model with SciPy’s `fsolve` or GEKKO to cross-check the solution.
5. **GPU Performance Tuning:** Once correctness is confirmed, test performance on the DGX. Profile the code to identify any bottlenecks (e.g. JAX may spend time compiling on first run – we can compile once and reuse the compiled function). Ensure that the entire solve indeed stays within the GPU (thanks to unified memory, we can avoid costly transfers). If needed, adjust the linear algebra approach – e.g. switch to an iterative linear solver if memory usage of a dense factorization is high, or exploit sparsity by using `jax.experimental.sparse` or SciPy’s sparse routines (with GPU offloading via CuPy). However, given 3k size, a dense solve is likely fine. We expect the toy model to solve in a few milliseconds; the full model with 3000 markets might take a bit longer per iteration, so we time a full run to ensure it’s well under 5 seconds. If it’s borderline, consider multi-GPU parallelization (though unlikely needed) or further optimizations (like precomputing parts of Jacobian structure).
6. **Introduce Extreme Scenarios:** Test the solver’s robustness on edge cases. For example, in the toy model impose a 300% tariff on a good or eliminate a trade route entirely (simulate an embargo by setting a particular import preference to zero and see if the solver drives that trade flow to zero with price adjustments). Observe if Newton iterations still converge. If oscillation or divergence is observed in these extreme cases, activate the fallback strategy: e.g. *homotopy continuation* – start by solving a milder version of the shock and then gradually increase it to the full shock, using each intermediate solution as the next initial guess. Automate this: the solver can detect divergence (residual norm not decreasing) and then split the shock into smaller increments internally. Another fallback is switching to a **gradient-based price adjustment loop**: if by iteration 15 Newton hasn’t converged, we can seamlessly transition to a Jacobi update p←p+α F(p)p \leftarrow p + \alpha\, F(p)p←p+αF(p) for a fixed number of iterations, or apply **Anderson acceleration** (which mixes past iterations to speed up convergence of fixed-point iterations). These techniques, while slower, will push the solution toward equilibrium from any state [copsmodels.com](https://www.copsmodels.com/ftp/workpapr/g-214.pdf#:~:text=match%20at%20L665%203,Raphson). We will code this contingency path so that it requires no manual intervention – the engine will simply log a warning that it used the backup method. In testing, verify that in a scenario like an embargo (which may create corner solutions), the solver either converges via damped Newton or cleanly switches to tatonnement and finds the equilibrium (which might have some prices at zero or changed regime).
7. **Library Integration (optional):** As a parallel effort, keep exploring if high-level libraries can complement our solver. For instance, set up the full 50×30 model in **Pyomo** to ensure we haven’t missed any equations and perhaps use IPOPT to solve a baseline scenario. This serves as an independent check on our custom solver’s results. Similarly, test a small case with **NEOS PATH** by submitting an AMPL formulation of the toy model to the NEOS server [neos-server.org](https://neos-server.org/neos/solvers/cp:PATH/AMPL.html#:~:text=The%20NEOS%20Server%20offers%20PATH,version%20of%20the%20PATH%20solver). If PATH finds a solution, compare its output and iteration count to our solver’s. Document any differences. This step isn’t strictly necessary for implementation, but it strengthens confidence and provides fallback options (e.g. if down the line a scenario proves very troublesome, one might quickly call PATH via NEOS as a double-check for the solution – noting that NEOS is not real-time, but good for one-off analysis).
8. **Full-Scale Deployment:** Scale up the model to 50 countries × 30 sectors using the same solver framework. This will involve reading in the actual data (e.g. a Social Accounting Matrix or GTAP data) and computing initial equilibrium p0p_0p0 from the dataset. Our solver can then be used to simulate any policy changes. We will integrate the solver into the simulation platform’s pipeline so that when a user introduces a shock (say a tariff change via the interface), the engine calls the solver to recompute the equilibrium. Ensure logging is in place – e.g. output the number of iterations and a convergence metric each run, so we can monitor performance over various scenarios. Given our tests, each simulation run should return equilibrium prices, trade flows, etc., within a couple of seconds on the DGX, providing a smooth user experience. We will also implement a **time-out or fail-safe**: if a solution isn’t found in e.g. 5 seconds (which is unlikely with our design), the system might either report an error or present the user with a message that the scenario is too extreme – but our prior steps aim to eliminate this possibility by robust algorithm design.
9. **Documentation and Fallback Procedures:** Document the solver’s usage and the economic interpretation of outputs. For maintainability, clearly comment the code, especially the Jacobian computations and any magic numbers (like damping coefficients). Also document the *fallback algorithm* triggering criteria and method. For example: *“If Newton method has not converged by iteration 15 or residual reduction < 1e-3, then activate tatonnement mode with $\alpha=0.1$ until convergence.”* This way the technical team can adjust these parameters in the future if needed. In addition, provide an **analytical appendix** for the record (perhaps in the code repository) detailing the equations solved and the solver logic – this will align with Dr. Maya Patel’s standards for technical rigor and allow any future team member to quickly grasp the inner workings.

By following this checklist, we ensure that we move from a conceptual solution to a tested, reliable implementation ready to be plugged into the simulation platform. The plan emphasizes stepwise validation (starting small, then scaling up) and building in robustness at every stage so that the end product meets the high performance and stability requirements.

## Research Roadmap and Pipeline Integration

*Figure: Equilibrium solver integration in the simulation pipeline.* The flowchart above outlines how the solver fits into the overall computation process, distinguishing which outputs are determined within the core equilibrium solution and which are calculated afterward from the results. Here’s the staged flow:

- **Scenario Input:** The process begins with scenario parameters (exogenous inputs) being fed in. These include policy shocks like tariff rates, quotas, technology changes, etc., along with the base data (e.g. initial endowments, production capacities). The user’s choices in the simulation interface (such as enacting a tariff hike or an embargo) are translated into numerical changes in these inputs.
- **Equilibrium Price Solver:** Given the updated scenario, the solver engine computes the new equilibrium **simultaneously for all markets**. This is the heart of the pipeline: it finds the set of prices (and possibly a few key quantity variables) such that every market clears (supply = demand). During this step, certain related variables are effectively determined as well. For instance, producers’ output levels adjust as a function of prices – in a Walrasian equilibrium, firms produce until marginal cost equals price, so once prices are known, output by sector is implicitly set (we can extract it). Likewise, household consumption of each good is pinned down by the equilibrium prices and incomes. In other words, the solver doesn’t just give prices in isolation; by clearing the markets it also establishes the consistent set of **production levels and consumption/trade allocations** that correspond to those prices. In our algorithm, these quantity adjustments occur within each function evaluation: whenever we guess prices, we compute how much each country would produce and consume, and those computations yield the excess demand used to adjust prices. Thus, when the solver converges, we have equilibrium prices *and* a provisional allocation of resources/trade that balances at those prices.
- **Post-solution Computations:** Once equilibrium prices $p^*$ are found, the pipeline moves to computing **derived outputs** that were not explicitly solved for, but are consequences of the equilibrium. This includes detailed **trade flows** between every pair of countries for each sector – using the equilibrium prices and any trade cost/tariff assumptions, we calculate how much of good X country A imports from country B, etc. (The equilibrium ensures aggregate imports equal exports for each good, but the bilateral breakdown might come from gravity equations or Armington share formulas.) Similarly, **production levels** by country and sector can now be finalized (though we effectively had them in computing $F(p)$, we now record them as results). We also update **balance sheets** for each country: government tariff revenue is calculated from the trade flows and tariff rates, trade balance is computed (exports minus imports value), and any changes in income or GDP can be tabulated. These figures are straightforward calculations given $p^*$ and the equilibrium quantities. They are done after the main solve to keep the solve focused only on essential variables. Keeping some variables out of the simultaneous solve (by computing them afterward from equilibrium prices) reduces the dimensionality of the core problem and improves speed without losing accuracy in results.
- **Welfare Metrics:** With the full equilibrium outcome (prices and quantities), we then compute welfare and other performance metrics. This could be as simple as real income or equivalent variation for each region, or consumer surplus changes, etc. For example, we might compute how a tariff scenario affected each country’s equivalent variation (a standard welfare measure) using the prices and consumption levels in equilibrium. These metrics rely on both the prices and quantities from the previous steps. We isolate them in the final step because they often involve summing up results or comparing to baseline, which conceptually occurs after the equilibrium is determined.
- **Output Delivery:** Finally, the pipeline outputs all these results to the user or downstream systems. The equilibrium prices feed into the game/simulation engine to update market conditions, the trade flows and production levels might be displayed as part of scenario outcomes (e.g. showing supply chain shifts), and welfare metrics are reported to inform the impact assessment (e.g. which countries gained or lost from a trade war scenario). The modular separation ensures that if we ever adjust how a metric is calculated, it doesn’t perturb the core equilibrium solver – the solver only cares about satisfying market-clearing with the behavioral equations, while the later stages care about reporting and analytics.

**Data dependencies:** Each arrow in the flowchart represents key dependencies. For instance, the solver’s outcome (prices and cleared quantities) is a prerequisite for computing trade flows – one needs the prices to know competitiveness of sources and the cleared quantities to know total trade volume. Trade flows in turn affect balance sheets (since tariff revenue = tariff * import value, etc.). And all of those feed into welfare calculations (consumer welfare depends on prices paid and quantity consumed, government welfare might include tariff revenue, etc.). By delineating which variables are solved simultaneously and which are subsequent calculations, we ensure clarity on what the solver must handle versus what can be layered on. If we find certain outputs are highly sensitive and maybe *should* be in the core solve, we can adjust the model (for example, if in some extension, a “welfare” metric needed to be optimized as part of equilibrium – not typical, but say a game theoretic equilibrium – we’d then include it). In our current design, the equilibrium solver focuses on **prices and market allocations**, while everything else is computed in a deterministic sweep afterward.

**Future enhancements:** As we operationalize this solver, there are a few avenues for continued research and improvement:

- **Scaling and Parallelism:** Our current problem size (~3,000 markets) is well-handled by a single GPU. If the model expands (e.g. more sectors, sub-national regions, or a dynamic multi-period extension), we might explore multi-GPU or distributed solutions. Libraries like JAX can compile across multiple devices, and we could partition the Jacobian if sparsity patterns allow (for instance, block-diagonal structures could be solved in parallel). Also, newer GPU architectures (like NVIDIA Blackwell) and software advances might let us solve even larger systems in similar time. We will keep an eye on algorithmic research such as the PDHCG method [arxiv.org](https://arxiv.org/html/2506.06258v1#:~:text=framework%20that%20integrates%20the%20primal,and%20applicability%20of%20market%20equilibrium) which could be beneficial if we encounter extremely large or more complex equilibrium problems (though for now Newton’s method is very efficient for us).
- **Robustness under model changes:** We plan to test the solver against a variety of extreme scenarios (not just tariffs/embargoes, but e.g. a collapse of a major economy’s output, or a sudden preference shift) to ensure it remains stable. If we discover scenarios where convergence is slow, we may refine our algorithm – e.g. tuning the damping logic or implementing **Anderson acceleration** for tatonnement steps to speed them up. The fallback procedures will be continuously evaluated: ideally they never need to trigger, but if they do, we want them to converge in acceptable time as well. This might involve adjusting the step-size $\alpha$ in the gradient descent or the increment size in homotopy based on performance.
- **Economic validation and refinement:** As this is a computational engine, we will also loop back to the economics. We’ll validate that the equilibrium outcomes make sense for extreme inputs (e.g. ensure that a 200% tariff in the model yields price changes and welfare effects that domain experts deem reasonable, not numerical artifacts). If any odd results appear, we may refine the model equations or add regularization (sometimes tiny taxes or small trade flows are added to avoid corner solutions that cause numerical issues). Ensuring economic meaningfulness will in turn keep the mathematics well-behaved.
- **Integration with Gameplay:** Since the solver is part of a simulation platform (likely with a user-facing game or scenario interface), we will align its outputs with the gameplay elements. For example, if the game requires explaining results to users in narrative form, we might incorporate a “reason generator” that uses the solver’s data (e.g. identifying that “wheat prices spiked because supply from Country X was cut off”). While not part of the solver per se, having quick access to solver outputs and possibly sensitivity analysis (via the Jacobian, we can tell which markets were most affected by a shock) could be a powerful feature for the platform. This is a strategic extension where the solver’s technical capability (fast, differentiable solution) directly enhances user experience by providing insights, not just numbers.
- **Appendices and Technical Reporting:** We will maintain thorough documentation (an internal technical appendix) capturing the equations, the calibration data sources, and the solver mathematics. This will satisfy the need for technical rigor (Dr. Patel’s framework) without burdening the main business-facing communication. For instance, we’ll keep records of the Jacobian formulas, any log files of solver iterations for extreme tests, and validation cases comparing solver outputs to known results or other solvers. This repository of knowledge ensures that if we revisit or upgrade the solver in the future (say to try a newer algorithm or incorporate uncertainty), we have a solid baseline to start from.

In summary, the project will deliver a **layered solution**: a fast and robust equilibrium computation core, surrounded by clear data flows and business-friendly output interpretation. We’ve chosen an algorithmic approach that balances cutting-edge speed (GPU-accelerated Newton solver) with reliability (proven economic convergence methods), aligning with our priorities of speed, stability, and openness. With the implementation plan and ongoing research roadmap laid out, we are confident this Equilibrium Solver Engine will meet the simulation platform’s real-time demands and maintain accuracy and transparency for all stakeholders.

**Sources:** Recent literature and tool documentation were consulted to ground these choices. Newton-based methods are known for fast convergence but require damping for global stability [pages.cs.wisc.edu](https://pages.cs.wisc.edu/~ferris/techreports/cstr1179.pdf#:~:text=is%20perhaps%20the%20most%20well,Recently%2C%20Grippo) [pages.cs.wisc.edu](https://pages.cs.wisc.edu/~ferris/techreports/cstr1179.pdf#:~:text=The%20Path%20solver%20is%20an,is%20shown%20to%20be%20globally), whereas simple price adjustment offers stability at the cost of speed [copsmodels.com](https://www.copsmodels.com/ftp/workpapr/g-214.pdf#:~:text=match%20at%20L665%203,Raphson). GPU-accelerated algorithms have demonstrated significant efficiency gains in large equilibrium computations [arxiv.org](https://arxiv.org/html/2506.06258v1#:~:text=framework%20that%20integrates%20the%20primal,and%20applicability%20of%20market%20equilibrium), and modern autodiff frameworks allow implementing multivariate Newton solvers succinctly [jax.quantecon.org](https://jax.quantecon.org/newtons_method.html#:~:text=Iteration%20starts%20from%20initial%20guess,p_0) [jax.quantecon.org](https://jax.quantecon.org/newtons_method.html#:~:text=f_jac%20%3D%20jax,1%20n%20%3D%200). We also referenced standard general equilibrium theory for validity of our formulation [fiveable.me](https://fiveable.me/introduction-to-mathematical-economics/unit-11/walrasian-equilibrium/study-guide/GVSDRkPHiJ5fIw9a#:~:text=,degree%20zero%2C%20and%20Walras%27%20Law) [fiveable.me](https://fiveable.me/introduction-to-mathematical-economics/unit-11/walrasian-equilibrium/study-guide/GVSDRkPHiJ5fIw9a#:~:text=Market%20clearing%20conditions). The design takes inspiration from the PATH solver’s success in handling complementarity in CGE models [pages.cs.wisc.edu](https://pages.cs.wisc.edu/~ferris/techreports/cstr1179.pdf#:~:text=The%20Path%20solver%20is%20an,is%20shown%20to%20be%20globally), without depending on proprietary software (though we note NEOS provides PATH for verification purposes [neos-server.org](https://neos-server.org/neos/solvers/cp:PATH/GAMS.html#:~:text=The%20NEOS%20Server%20offers%20PATH,version%20of%20the%20PATH%20solver)). The chosen approach leverages open-source Python libraries (JAX/PyTorch) and known solvers (SciPy, IPOPT, etc.) where appropriate [github.com](https://github.com/BYU-PRISM/GEKKO#:~:text=GEKKO%20provides%20a%20user,quadratic%2C%20nonlinear%2C%20and%20mixed). This ensures our solution is both cutting-edge and grounded in proven techniques, delivering real-time equilibrium analysis for the simulation.

## Figures

### Core Loop: Price Adjustment to Equilibrium
```mermaid
graph TD
    A [Initial Guess: Prices p₀] --> B [Compute Excess Demand<br/> Demand - Supply]
    B --> C{Are All Markets Balanced?}
    C -->|No| D [Adjust Prices Using Newton + Damping]
    D --> A
    C -->|Yes| E [Equilibrium Found!<br/>Return Prices and Quantities]
    
    style E fill:#51cf66
    style D fill:#ffd43b
```
### Algorithm Comparison Table

```mermaid

flowchart TD
    subgraph Comparison: Algorithm Tradeoffs
        T1 [Tâtonnement]
        T2 [Newton-Raphson]
        T3 [PATH Solver]
    end
    T1 -->|Speed| A1(Slow)
    T1 -->|Stability| B1(Very Stable)
    T1 -->|Ease| C1(Very Easy)
    T1 -->|Cost| D1(Free)

    T2 -->|Speed| A2(Fast)
    T2 -->|Stability| B2(Needs Damping)
    T2 -->|Ease| C2(Medium)
    T2 -->|Cost| D2(Free)

    T3 -->|Speed| A3(Very Fast)
    T3 -->|Stability| B3(Very Stable)
    T3 -->|Ease| C3(Black Box)
    T3 -->|Cost| D3(\$300+)

    style T2 fill:#ffd43b
    style T3 fill:#ffe066
```
### Before vs After a Tariff Shock
```mermaid
graph LR
    subgraph "Before Tariff"
        A1 [Price: Steel = $100]
        B1 [Trade: Import 50k tons]
    end

    subgraph "After Tariff"
        A2 [Price: Steel = $135]
        B2 [Trade: Import 15k tons]
    end

    A1 --> B1
    A2 --> B2
```
### What Gets Solved When

```mermaid
graph TD
    A [User Triggers Policy Change] --> B [Equilibrium Solver: Solve Prices & Allocations]
    B --> C1 [Prices per Good x Country]
    B --> C2 [Production Levels]
    B --> C3 [Aggregate Trade Volumes]

    C1 --> D1 [Post-Solve: Bilateral Trade Flows]
    C1 --> D2 [Welfare Metrics]
    C2 --> D3 [Sector Employment]
    C3 --> D4 [Balance of Payments]

    style B fill:#ff6b6b
    style D1 fill:#ffd43b
    style D2 fill:#ffd43b
    style D3 fill:#ffd43b
    style D4 fill:#ffd43b

```

### Fallback Logic Trigger Path

```mermaid
graph TD
    A [Start Newton Solver] --> B{Converging?}
    B -->|Yes| C [Done – Use Equilibrium Result]
    B -->|No| D{Too Many Iterations?}
    D -->|No| A
    D -->|Yes| E [Trigger Fallback: Tatonnement]
    E --> F{Converged?}
    F -->|Yes| G [Done – Use Fallback Result]
    F -->|No| H [Report Error or Use Homotopy Path]

    style E fill:#ffd43b
    style G fill:#51cf66
    style H fill:#ff6b6b
```

### Solver Integration Pipeline
```mermaid
graph TD
    A [Player Action<br/>Tariff, Ban, Subsidy] --> B [Policy Module]
    B --> C [Demand, Supply, Trade Data Update]
    C --> D [Equilibrium Solver Engine]

    D --> E1 [Equilibrium Prices]
    D --> E2 [Trade Flows]
    D --> E3 [Production by Sector]
    D --> E4 [Country Balances]

    E1 --> F [Player Dashboard]
    E2 --> F
    E3 --> F
    E4 --> F
    style D fill:#ff6b6b
    style F fill:#51cf66
```